{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import kaiming_normal_, kaiming_uniform_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.5734, -1.2485,  0.5629,  0.7896, -0.4293,  0.9726, -1.4301,  0.6779,\n",
       "          0.8384, -0.7334,  0.7964,  1.6117, -0.9399,  1.1813,  0.0902, -0.8812,\n",
       "         -0.8176, -0.9856, -0.2382, -1.0007, -1.5119,  0.6298, -0.0136, -0.4105,\n",
       "         -0.7050, -0.0282,  0.3113,  0.8288, -0.5914, -0.6119, -0.8549, -0.7866,\n",
       "          0.8864,  0.8158,  0.5732,  1.3631, -0.2000,  0.9504, -2.1211,  0.5665,\n",
       "          0.7490,  1.0691,  0.1702, -0.8173, -0.6776, -1.5998, -1.1331, -0.9786,\n",
       "          0.4729, -0.3974, -0.9547, -1.0017, -0.7745,  1.0788, -1.1509,  1.1367,\n",
       "         -0.0552,  0.1882, -0.0894,  0.8276, -0.3104,  0.6693, -0.9399, -0.7496,\n",
       "         -1.1902, -0.7327,  1.8143, -0.6053,  0.0726, -0.1611, -0.9829, -0.6636,\n",
       "         -0.5799,  0.4069, -2.1520, -1.2220,  0.1452, -0.8232,  0.2868,  0.2490,\n",
       "         -0.7190,  0.2694, -2.6760, -1.1018,  1.1614, -1.0078, -0.4168,  0.0146,\n",
       "         -0.2599, -0.3227,  0.6746, -0.1666,  0.6217, -1.0345,  0.5248, -1.3923,\n",
       "          0.6642, -1.9983,  0.3854, -1.0385], device='mps:0',\n",
       "        requires_grad=True),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='mps:0'))"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1244)\n",
    "input = torch.randn(100, dtype=torch.float, device='mps', requires_grad=True)\n",
    "y = torch.zeros_like(input)\n",
    "y[0] = 1\n",
    "input, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __init__(self, linear_in, linear_out):\n",
    "        # self.w = torch.randn(linear_in, linear_out, requires_grad=True, device='mps')\n",
    "        self.w = torch.empty(linear_in, linear_out, device='mps')\n",
    "        kaiming_uniform_(self.w)\n",
    "        self.w.requires_grad_(True)\n",
    "    def __call__(self, x):\n",
    "        a = x @ self.w\n",
    "        a = F.gelu(a)\n",
    "        return torch.softmax(a, 0)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(100, 100, bias=False, device='mps', dtype=torch.float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.gelu(self.linear1(x))\n",
    "        return torch.softmax(x, 0)\n",
    "\n",
    "module = Module(100, 100)\n",
    "myModule = MyModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0299,  0.1393,  0.2279,  ...,  0.2317,  0.0913, -0.0622],\n",
      "        [ 0.0544,  0.2054, -0.2110,  ..., -0.2354,  0.2142, -0.0552],\n",
      "        [-0.1136, -0.1403,  0.2341,  ...,  0.2169, -0.1314,  0.1425],\n",
      "        ...,\n",
      "        [-0.0288, -0.1261,  0.1990,  ..., -0.0904, -0.0309,  0.1893],\n",
      "        [-0.1185, -0.2103, -0.1323,  ..., -0.2065,  0.1864, -0.1170],\n",
      "        [-0.0663,  0.0811, -0.0772,  ...,  0.1881,  0.1048,  0.2442]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "tensor(1.0430, device='mps:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = module(input)\n",
    "print(module.w)\n",
    "Loss = torch.sum((out - y).pow(2))  # pow(2) is equivalent to squaring\n",
    "print(Loss)\n",
    "\n",
    "Loss.backward()\n",
    "# module.w.requires_grad_(False)\n",
    "with torch.no_grad():\n",
    "    module.w -= 1.0 * module.w.grad\n",
    "    module.w.grad.zero_()\n",
    "# module.w.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9955, device='mps:0', grad_fn=<SumBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.0890,  0.0133,  0.0824,  ...,  0.0540, -0.0632,  0.0349],\n",
      "        [-0.0251,  0.0142, -0.0222,  ..., -0.0363, -0.0629,  0.0124],\n",
      "        [ 0.0216,  0.0070, -0.0396,  ...,  0.0342, -0.0881, -0.0594],\n",
      "        ...,\n",
      "        [ 0.0995,  0.0429,  0.0062,  ...,  0.0797, -0.0206,  0.0346],\n",
      "        [-0.0702,  0.0053,  0.0986,  ...,  0.0793,  0.0175,  0.0300],\n",
      "        [-0.0371,  0.0388, -0.0105,  ..., -0.0840,  0.0536, -0.0370]],\n",
      "       device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "out = myModule(input)\n",
    "# print(out)\n",
    "Loss = torch.sum((out - y).pow(2))  # pow(2) is equivalent to squaring\n",
    "print(Loss)\n",
    "\n",
    "Loss.backward()\n",
    "with torch.no_grad():\n",
    "    for p in myModule.linear1.parameters():\n",
    "        p -= 1.0 * p.grad\n",
    "        p.grad.zero_()\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory Profiling\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CUDA],\n",
    "        profile_memory=True, record_shapes=True) as prof:\n",
    "    out = myModule(input)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinda_default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
